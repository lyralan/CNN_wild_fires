{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T07:34:07.864886Z",
     "start_time": "2021-08-12T07:34:07.861771Z"
    }
   },
   "outputs": [],
   "source": [
    "from u import *\n",
    "import PIL\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T07:34:08.862971Z",
     "start_time": "2021-08-12T07:34:08.860529Z"
    }
   },
   "outputs": [],
   "source": [
    "Base = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:21:30.051345Z",
     "start_time": "2021-08-12T20:21:27.211699Z"
    }
   },
   "outputs": [],
   "source": [
    "fire = Base / 'california_fire_perimeters.kml'\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse(fire)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:26:03.273175Z",
     "start_time": "2021-08-12T20:25:59.097872Z"
    }
   },
   "outputs": [],
   "source": [
    "fire = {}\n",
    "for child in root[0][1][1:]:\n",
    "#     print(child.tag, child.attrib)\n",
    "    area = None\n",
    "    month = None\n",
    "    for attr in child[1][0]:\n",
    "        if attr.attrib['name'] == 'GIS_ACRES':\n",
    "            area = float(attr.text)\n",
    "            break\n",
    "    for attr in child[1][0]:\n",
    "        if attr.attrib['name'] == 'ALARM_DATE':\n",
    "            month = int(attr.text.split('/')[1])\n",
    "            break\n",
    "    if area == None:\n",
    "        continue\n",
    "    cord = child[2][0][0][0][0].text\n",
    "    cord = cord.split(' ')\n",
    "    \n",
    "    lon_list = []\n",
    "    lat_list = []\n",
    "    for x in cord:\n",
    "        lon, lat = map(float, x.split(','))\n",
    "        lon_list.append(lon)\n",
    "        lat_list.append(lat)\n",
    "    lon = np.mean(lon_list)\n",
    "    lat = np.mean(lat_list)\n",
    "    fire[(lon, lat)] = (area, month) # acre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:26:03.296150Z",
     "start_time": "2021-08-12T20:26:03.275014Z"
    }
   },
   "outputs": [],
   "source": [
    "location = np.array(list(fire.keys()))\n",
    "min_lon, min_lat = location.min(axis=0) \n",
    "max_lon, max_lat = location.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:26:03.300218Z",
     "start_time": "2021-08-12T20:26:03.297638Z"
    }
   },
   "outputs": [],
   "source": [
    "minx = int(min_lon * 120 + 120 * 180) - 50\n",
    "maxx = int(max_lon * 120 + 120 * 180) + 1 + 50\n",
    "maxy = int(90 * 120 - min_lat * 120) + 1 + 50\n",
    "miny = int(90 * 120 - max_lat * 120) - 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# meteorology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T07:34:00.858042Z",
     "start_time": "2021-08-12T07:34:00.851255Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "def func(path):\n",
    "    print(path)\n",
    "    name = path.replace('tif','npy')\n",
    "    if name.exists():\n",
    "        return \n",
    "    im = Image.open(path)\n",
    "    im = np.array(im)\n",
    "    ca = im[miny:maxy, minx:maxx]\n",
    "    with open(name, 'wb') as f:\n",
    "        np.save(f, ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T07:35:06.958290Z",
     "start_time": "2021-08-12T07:34:21.819616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/worldclim/temperature_average/wc2.1_30s_tavg_06.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_11.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_02.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_01.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_05.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_10.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_07.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_12.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_03.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_08.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_04.tif\n",
      "data/worldclim/temperature_average/wc2.1_30s_tavg_09.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_09.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_03.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_07.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_12.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_05.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_06.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_10.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_04.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_01.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_02.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_11.tif\n",
      "data/worldclim/wind/wc2.1_30s_wind_08.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_10.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_09.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_01.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_05.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_04.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_08.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_07.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_11.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_03.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_02.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_06.tif\n",
      "data/worldclim/vapor/wc2.1_30s_vapr_12.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_09.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_03.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_11.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_08.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_06.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_12.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_04.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_01.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_02.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_10.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_05.tif\n",
      "data/worldclim/precipitation/wc2.1_30s_prec_07.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_08.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_03.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_02.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_09.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_06.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_07.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_10.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_11.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_05.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_12.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_01.tif\n",
      "data/worldclim/solar/wc2.1_30s_srad_04.tif\n"
     ]
    }
   ],
   "source": [
    "files = (Base /'worldclim').glob('*/*.tif')\n",
    "# with Pool(48) as pool:\n",
    "#     list(pool.imap(func, files))\n",
    "# for file in files:\n",
    "#     func(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:16:35.172210Z",
     "start_time": "2021-08-12T20:16:31.527222Z"
    }
   },
   "outputs": [],
   "source": [
    "stacked = {}\n",
    "for mon in range(1, 13):\n",
    "    files = sorted((Base /'worldclim').glob(f'*/*{mon:02d}.npy'))\n",
    "    stack = []\n",
    "    for file in files:\n",
    "        x = np.load(file)\n",
    "        if file._up._name == 'temperature_average':\n",
    "            x[x == x.min()] = 0\n",
    "            x = x / 25\n",
    "        elif file._up._name == 'solar':\n",
    "            x[x == x.max()] = 0\n",
    "            x = x / x.max()\n",
    "        elif file._up._name in ['vapor', 'wind', 'precipitation']:\n",
    "            x[x == x.min()] = 0\n",
    "            x = x / x.max()\n",
    "        stack.append(x)\n",
    "    stack = np.array(stack)\n",
    "    stacked[mon] = stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:40:53.837253Z",
     "start_time": "2021-08-12T20:40:53.213393Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "for (lon, lat), (area, month) in fire.items():\n",
    "    x = int(lon * 120 + 120 * 180) \n",
    "    y = int(120 * 90 - lat * 120) \n",
    "    if month != None:\n",
    "        c_lat = y - miny\n",
    "        c_lon = x - minx\n",
    "        inputs.append(stacked[month][:, c_lat - 25 : c_lat + 26, c_lon - 25 : c_lon + 26])\n",
    "        outputs.append(area)\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:42:43.363808Z",
     "start_time": "2021-08-12T20:42:42.944177Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, outputs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T20:47:20.624452Z",
     "start_time": "2021-08-12T20:47:20.242439Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T22:30:48.208468Z",
     "start_time": "2021-08-12T22:30:48.203325Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(5, 32, 4, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(12, stride=None)\n",
    "        )\n",
    "        self.fc = nn.Sequential(nn.Linear(128, 256), nn.ReLU(), nn.Linear(256, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.convs(x)\n",
    "        return self.fc(embedding.squeeze(2).squeeze(2)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T22:43:08.175274Z",
     "start_time": "2021-08-12T22:43:07.281751Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_concat = np.concatenate([x_train, x_train[:, :, ::-1, :]])\n",
    "y_train_concat = np.concatenate([y_train, y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T22:43:12.677775Z",
     "start_time": "2021-08-12T22:43:08.870643Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_concat = np.concatenate([x_train_concat, \n",
    "                                 np.rot90(x_train_concat, 1, axes=(2,3)), \n",
    "                                 np.rot90(x_train_concat, 2, axes=(2,3)), \n",
    "                                 np.rot90(x_train_concat, 3, axes=(2,3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T22:43:26.094942Z",
     "start_time": "2021-08-12T22:43:26.091166Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_concat = np.concatenate([y_train_concat, y_train_concat, y_train_concat, y_train_concat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T22:46:21.645514Z",
     "start_time": "2021-08-12T22:46:21.539475Z"
    }
   },
   "outputs": [],
   "source": [
    "net = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T22:46:38.655930Z",
     "start_time": "2021-08-12T22:46:38.652948Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T23:22:46.797054Z",
     "start_time": "2021-08-12T23:21:57.656115Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 validation loss = 411812512.0\n",
      "Step 100 validation loss = 412282880.0\n",
      "Step 150 validation loss = 411876736.0\n",
      "Step 200 validation loss = 412320416.0\n",
      "Step 250 validation loss = 411885856.0\n",
      "Step 300 validation loss = 411561568.0\n",
      "Step 350 validation loss = 411903168.0\n",
      "Step 400 validation loss = 411693984.0\n",
      "Step 450 validation loss = 411559904.0\n",
      "Step 500 validation loss = 411565024.0\n",
      "Step 550 validation loss = 411933600.0\n",
      "Step 600 validation loss = 411747296.0\n",
      "Step 650 validation loss = 411430912.0\n",
      "Step 700 validation loss = 412149152.0\n",
      "Step 750 validation loss = 411766368.0\n",
      "Step 800 validation loss = 411450624.0\n",
      "Step 850 validation loss = 411777888.0\n",
      "Step 900 validation loss = 412261408.0\n",
      "Step 950 validation loss = 411501600.0\n",
      "Step 1000 validation loss = 411549536.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(n_steps):\n",
    "    Sample a batch of size n_batch x and y from the training set\n",
    "    Convert x_batch and y_batch to torch.tensor\n",
    "    feed x_batch_tensor into net to get y_pred_batch\n",
    "    compute (MSE) loss between y_pred_batch and y_batch\n",
    "    compute gradient for the net parameters given the loss\n",
    "    optimizer update the parameters given the gradient\n",
    "\"\"\"\n",
    "\n",
    "def evaluate(net, x_test, y_test):\n",
    "    with torch.no_grad():\n",
    "        x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "        y_pred = net(x_test_tensor)\n",
    "        loss = F.mse_loss(y_pred, y_test_tensor)\n",
    "        return loss\n",
    "\n",
    "n_steps = 1000\n",
    "n_eval_steps = 50\n",
    "n_batch = 100\n",
    "for i in range(n_steps):\n",
    "    indices = np.random.choice(len(x_train_concat), size=n_batch)\n",
    "    x_batch = x_train_concat[indices]\n",
    "    y_batch = y_train_concat[indices]\n",
    "    x_batch_tensor = torch.tensor(x_batch, dtype=torch.float32)\n",
    "    y_batch_tensor = torch.tensor(y_batch, dtype=torch.float32)\n",
    "    y_batch_pred = net(x_batch_tensor)\n",
    "    loss = F.mse_loss(y_batch_pred, y_batch_tensor)\n",
    "    optimizer.zero_grad() # clear previous gradient\n",
    "    loss.backward() # back propagation to get the gradient\n",
    "    optimizer.step() # optimizer applies gradient to the parameters\n",
    "    \n",
    "    if (i + 1) % n_eval_steps == 0:\n",
    "        loss = evaluate(net, x_test, y_test)\n",
    "        print(f'Step {i+1} validation loss = {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
